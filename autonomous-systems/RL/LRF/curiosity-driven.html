<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Curiosity-driven Exploration by Self-supervised Prediction</title>
        
        


        <!-- Custom HTML head -->
        


        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        
        <link rel="icon" href="../../../favicon.svg">
        
        
        <link rel="shortcut icon" href="../../../favicon.png">
        
        <link rel="stylesheet" href="../../../css/variables.css">
        <link rel="stylesheet" href="../../../css/general.css">
        <link rel="stylesheet" href="../../../css/chrome.css">
        
        <link rel="stylesheet" href="../../../css/print.css" media="print">
        

        <!-- Fonts -->
        <link rel="stylesheet" href="../../../FontAwesome/css/font-awesome.css">
        
        <link rel="stylesheet" href="../../../fonts/fonts.css">
        

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="../../../highlight.css">
        <link rel="stylesheet" href="../../../tomorrow-night.css">
        <link rel="stylesheet" href="../../../ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        

        
        <!-- MathJax -->
        <script async type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
        
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "../../../";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded "><a href="../../../meta-learning/index.html"><strong aria-hidden="true">1.</strong> Meta-Learning</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../../meta-learning/MAML.html"><strong aria-hidden="true">1.1.</strong> Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks</a></li><li class="chapter-item expanded "><a href="../../../meta-learning/MAML++.html"><strong aria-hidden="true">1.2.</strong> HOW TO TRAIN YOUR MAML</a></li><li class="chapter-item expanded "><a href="../../../meta-learning/ANIL.html"><strong aria-hidden="true">1.3.</strong> RAPID LEARNING OR FEATURE REUSE? TOWARDS UNDERSTANDING THE EFFECTIVENESS OF MAML</a></li><li class="chapter-item expanded "><a href="../../../meta-learning/FO-MAML.html"><strong aria-hidden="true">1.4.</strong> On First-Order Meta-Learning Algorithms</a></li><li class="chapter-item expanded "><a href="../../../meta-learning/HF-MAML.html"><strong aria-hidden="true">1.5.</strong> On the Convergence Theory of Gradient-Based Model-Agnostic Meta-Learning Algorithms</a></li><li class="chapter-item expanded "><a href="../../../meta-learning/iMAML.html"><strong aria-hidden="true">1.6.</strong> Meta-Learning with Implicit Gradients</a></li></ol></li><li class="chapter-item expanded "><a href="../../../autonomous-systems/index.html"><strong aria-hidden="true">2.</strong> Autonomous Systems</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../../autonomous-systems/planning&decision-making.html"><strong aria-hidden="true">2.1.</strong> [review]Planning and Decision-Making for Autonomous Vehicles</a></li><li class="chapter-item expanded "><a href="../../../autonomous-systems/motion-planning-review.html"><strong aria-hidden="true">2.2.</strong> [review]A Review of Mobile Robot Motion Planning Methods</a></li><li class="chapter-item expanded "><a href="../../../autonomous-systems/RL/index.html"><strong aria-hidden="true">2.3.</strong> RL</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../../autonomous-systems/RL/A3C.html"><strong aria-hidden="true">2.3.1.</strong> Asynchronous Methods for Deep Reinforcement Learning (A3C)</a></li><li class="chapter-item expanded "><a href="../../../autonomous-systems/RL/LRF/curiosity-driven.html" class="active"><strong aria-hidden="true">2.3.2.</strong> Curiosity-driven Exploration by Self-supervised Prediction</a></li><li class="chapter-item expanded "><a href="../../../autonomous-systems/RL/LRF/end-to-end nav strategy with DRL.html"><strong aria-hidden="true">2.3.3.</strong> End-to-End Navigation Strategy With Deep Reinforcement Learning for Mobile Robots</a></li></ol></li></ol></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                        
                    </div>

                    <h1 class="menu-title"></h1>

                    <div class="right-buttons">
                        
                        <a href="../../../print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        
                        
                        

                    </div>
                </div>

                
                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>
                

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="curiosity-driven-exploration-by-self-supervised-prediction"><a class="header" href="#curiosity-driven-exploration-by-self-supervised-prediction">Curiosity-driven Exploration by Self-supervised Prediction</a></h1>
<p>In many real-world scenarios, rewards extrinsic to the agent are extremely sparse or missing altogether, and it is not possible to construct a shaped reward function.</p>
<p>In reinforcement learning, intrinsic motivation/rewards become critical whenever extrinsic rewards are sparse.</p>
<p>Two broad classes:</p>
<ul>
<li>encourage the agent to explore “novel” states</li>
<li>encourage the agent to perform actions that reduce the error/uncertainty in the agent’s ability to predict the consequence of its own actions</li>
</ul>
<p>The effectiveness of curiosity formulation in all three of these roles:</p>
<ul>
<li>solving tasks with sparse rewards</li>
<li>helps an agent explore its environment in the quest for new knowledge</li>
<li>learn skills that might be helpful in future scenarios</li>
</ul>
<h2 id="curiosity-driven-exploration"><a class="header" href="#curiosity-driven-exploration">Curiosity-Driven Exploration</a></h2>
<p>Intrinsic curiosity reward generated by the agent at time t: \(r_t^i\), extrinsic reward: \(r_t^e\), sum: \(r_t = r_t^i + r_t^e\), with \(r_t^e\) mostly zero.</p>
<p>Policy: \(\pi(s_t ; \theta_P)\) by a deep neural network with parameters \(\theta_P\).</p>
<p>Given the agent in state \(s_t\), it executes the action \(a_t \sim \pi(s_t ; \theta_P)\).</p>
<p>\(\theta_P\) is optimized to maximize the expected sum of rewards:</p>
<p>$$
\max_{\theta_P} \mathbb{E}_{\pi(s_t ; \theta_P)} [\Sigma_t r_t]
$$</p>
<p>Asynchronous advantage actor critic policy gradient (A3C).</p>
<h3 id="prediction-error-as-curiosity-reward"><a class="header" href="#prediction-error-as-curiosity-reward">Prediction error as curiosity reward</a></h3>
<p>If not the raw observation space, then what is the right feature space for making predictions so that the prediction error provides a good measure of curiosity?</p>
<p>Divide all sources that can modify the agent’s observations into three cases:</p>
<ul>
<li>things that can be controlled by the agent;</li>
<li>things that the agent cannot control but that can affect the agent (e.g. a vehicle driven by another agent), and</li>
<li>things out of the agent’s control and not affecting the agent (e.g. moving leaves).</li>
</ul>
<p>A good feature space for curiosity should model (1) and (2) and be unaffected by (3).</p>
<h3 id="self-supervised-prediction-for-exploration"><a class="header" href="#self-supervised-prediction-for-exploration">Self-supervised prediction for exploration</a></h3>
<p>A general mechanism for learning feature representations such that the prediction error in the learned feature space provides a good intrinsic reward signal.</p>
<p>Train a deep neural network with two sub-modules:</p>
<ul>
<li>the first submodule encodes the raw state \((s_t)\) into a feature vector \(\phi(s_t)\).</li>
<li>the second submodule takes as inputs the feature encoding \(\phi(s_t), \phi(s_{t+1})\) of two consequent states and predicts the action \((a_t)\) taken by the agent to move from state \(s_t\) to \(s_{t+1}\).</li>
</ul>
<p>Training this neural network amounts to learning function \(g\) defined as:</p>
<p>$$
\hat{a}<em>t = g(s_t, s</em>{t+1} ; \theta_I)
$$</p>
<p>The neural network parameters \(\theta_I\) are trained to optimize:</p>
<p>$$
\min_{\theta_I} L_I(\hat{a}<em>t, a_t)
$$
The learned function \(g\) is also known as the <strong>inverse dynamics model</strong> and the tuple \((s_t, a_t, s</em>{t+1})\) required to learn \(g\) is obtained while the agent interacts with the environment using its current policy \(\pi(s)\).</p>
<p>Train another neural network:</p>
<p>$$
\hat{\phi}(s_{t+1}) = f(\phi(s_t), a_t ; \theta_F)
$$</p>
<p>The neural network parameters \(\theta_F\) are optimized by minimizing the loss function \(L_F\):</p>
<p>$$
L_F(\phi(s_t), \hat{\phi}(s_{t+1})) = \frac{1}{2} \parallel \hat{\phi}(s_{t+1}) - \phi(s_{t+1}) \parallel _2^2
$$</p>
<p>The learned function \(f\) is also known as the <strong>forward dynamics model</strong>.</p>
<p>The intrinsic reward signal is computed as:</p>
<p>$$
r_t^i = \frac{\eta}{2} \parallel \hat{\phi}(s_{t+1}) - \phi(s_{t+1}) \parallel _2^2
$$</p>
<p>Intrinsic Curiosity Module (ICM).</p>
<p>The overall optimization problem:</p>
<p>$$
\min_{\theta_P, \theta_I, \theta_F} [-\lambda \mathbb{E}_{\pi(s_t;\theta_P)}[\Sigma_t r_t] + (1-\beta) L_I + \beta L_F], 0 \leq \beta \leq 1, \lambda &gt; 0.
$$</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        
                            <a rel="prev" href="../../../autonomous-systems/RL/A3C.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>
                        

                        
                            <a rel="next" href="../../../autonomous-systems/RL/LRF/end-to-end nav strategy with DRL.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>
                        

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                
                    <a rel="prev" href="../../../autonomous-systems/RL/A3C.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>
                

                
                    <a rel="next" href="../../../autonomous-systems/RL/LRF/end-to-end nav strategy with DRL.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
                
            </nav>

        </div>

        

        

        

        
        <script type="text/javascript">
            window.playground_copyable = true;
        </script>
        

        

        
        <script src="../../../elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../../mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../../searcher.js" type="text/javascript" charset="utf-8"></script>
        

        <script src="../../../clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../../highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../../book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        

        

    </body>
</html>
