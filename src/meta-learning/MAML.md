# Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks

作者将元学习问题形式化后提出了一个模型无关的元学习算法MAML。

## 问题设置

用 \\(f\\) 表示一个机器学习中模型，可以将输入分布中的一个观测 \\(x\\) 映射到输出 \\(a\\) 。

元学习中，每个任务表示为 \\(T=\{L(x_1,a_1,..,x_H,a_H),q(x_1),q(x_{t+1}|x_t,a_t),H\}\\)，其中 \\(L(x_1,a_1,..,x_H,a_H)\rightarrow \mathbb{R}\\) 为损失函数，\\(q(x_1)\\) 表示初始观测 \\(x_1\\) 的分布，而 \\(q(x_{t+1}|x_t,a_t)\\) 表示转移的分布，用于适应不同模型。对于i.i.d的监督学习，\\(H=1\\)。

考虑学习任务的分布 \\(p(T)\\) ，元学习要学习的就是该分布。在K样本(K-shot)的学习中，元学习的训练使用分布 \\(p(T)\\) 中的任务 \\(T_i\\)，然后用该任务中 \\(q_i\\) 的K个样本和 \\(L_{T_i}\\) 进行训练，并用 \\(T_i\\) 中新的样本进行测试，得到的测试误差用作整个元学习的训练误差。最终使用分布 \\(p(T)\\) 采样的新任务来测试元学习模型。

## MAML算法

算法目标是寻找敏感的模型参数，使得其面对分布 \\(p(T)\\) 中新的任务时，对参数较小的修改就可以使新任务的模型产生很大的提升。算法对模型没有假设，只假设其可以用一组参数 \\(\theta\\) 表示，并且其可以使用基于梯度的学习技术来更新。

元学习算法中，每个任务中的模型用 \\(f_{\theta}\\) 表示，并对于一个新的任务 \\(T_i\\) ，模型适应后参数记为 \\(\theta_i'\\) ，其可以通过一次或多次梯度下降得到，每次梯度下降可以表示为：

$$
    \theta_i' = \theta - \alpha \nabla_\theta L_{T_i}(f_\theta)
$$

其中 \\(\alpha\\) 为超参数或可以被元学习。

元学习的目标是将模型 \\(f_{\theta_i'}\\) 的效果最优化：

$$
    \min_{\theta}\sum_{T_i \sim p(T)}L_{T_i}(f_{\theta_i'})=\sum_{T_i \sim p(T)}L_{T_i}(f_{\theta - \alpha \nabla_\theta L_{T_i}(f_\theta)})
$$

学习目标最终体现在得到的模型参数\\(\theta\\)中：

$$
    \theta \leftarrow \theta - \beta \nabla_\theta \sum_{T_i \sim p(T)}L_{T_i}(f_{\theta_i'})
$$

MAML对新的任务，使用该参数\\(\theta\\)经过较少的新任务中的样本训练后，就可以得到很好的效果。

### 监督学习(回归和分类)

设置\\(H=1\\)。

对于回归类的任务，使用MSE：

$$
    L_{T_i}(f_{\phi})=\sum_{x^{(j)},y^{(j)} \sim T_i}||f_\phi(x^{(j)})-y^{(j)}||^2_2
$$

其中，\\(x^{(j)},y^{(j)}\\)为任务\\(T_i\\)的样本对，K样本的回归任务中，每个任务取K个进行训练。

对于离散的分类任务，使用cross entropy：

$$
    L_{T_i}(f_{\phi})=\sum_{x^{(j)},y^{(j)} \sim T_i}y^{(j)}log f_\phi(x^{(j)})+(1-y^{(j)})log (1-f_\phi(x^{(j)}))
$$

K样本N分类任务的训练中，每一类需要K个样本，每个任务需要NK个数据。

### 强化学习

每个强化学习任务包含初始状态分布\\(q_i(x_1)\\) ，一个转移分布 \\(q_i(x_{t+1}|x_t,a_t)\\) 和由(负的)奖励函数\\(R\\)定义的损失函数\\(L_{T_i}\\)。整个任务是一个马尔可夫决策过程，长度为H。学习的模型\\(f_\theta\\)可以将每一步\\(t\in{1,...,H}\\)的\\(x_t\\)状态映射到一个动作\\(a_t\\)上。形式为：

$$
    L_{T_i}(f_\phi)=-\mathbb{E_{x_t,a_t \sim f_\phi,q_{T_i}}}[\sum_{t=1}^{H}R_i(x_t,a_t)]
$$

## 测试结果


